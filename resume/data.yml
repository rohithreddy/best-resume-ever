/* #*/ export const PERSON = `
name:
  first: Rohith
  middle:
  last: Reddy


computer_skills:
- type: Languages
  list: Python, Javascript, Java
- type: Frameworks
  list: Flask, Falcon, Pandas, Backbone.js, Airflow, Spring, Spark, Kafka, Chalice, Selenium, Dask
- type: Databases
  list: MySQL, PostgreSQL, MongoDB, Druid, DynamoDB, Redshift
- type: Dev tools
  list: Git, Nginx, Shell, Intellij, VS Code, Docker, AWS CDK
- type: Hosting
  list: AWS, GCP


experience:
- company: Sphota
  place: Bangalore
  position: Member of Technical Staff
  timeperiod: Sep 2018 - Aug 2019
  tech_stack: Falcon, PostgreSQL, Python, PubSub, CloudFunctions, CloudScheduler, Vegeta
  product_name: Paid Search Platform
  url: https://sphota.biz
  description: 
    - d_item: Developed high-performance ad trackers using Falcon, PubSub for multi-touch attribution modeling
    - d_item: Designed and developed scalable processing pipeline based on Google Cloud Functions and Cloud Scheduler
    - d_item: Built reporting system to help marketers gain insights on Ad Spends
    - d_item: Made changes related to GDPR in internal data platform for Fortune 500 client

- company: Niyo
  place: Bangalore
  position: Data Engineer
  timeperiod: Jun 2017 - Apr 2018
  tech_stack: Airflow, S3, Redshift, Metabase, Python, Pandas, Kafka, React.js, Spring, EC2
  product_name: Niyo Card Products
  url: https://www.goniyo.com
  description: 
    - d_item: Built centralized data warehouse handling transactional data generated by 3 lakh users based on Redshift using ELT methodology
    - d_item: Developed and curated business intelligence system on Metabase, trained internal users in using it, enabling our organization to be data-driven
    - d_item: Created dashboards with 8-ball metrics for investors to gain insights on business contributing towards Series A funding of $13.2 Million
    - d_item: Implemented data quality checks leading to rectify bugs in partner's services causing erroneous transactions
    - d_item: Automated sharing data with partners, various reports for invoicing and compliance using Airflow


- company: RedBlackTree
  place: Chennai
  position: Serverside IOT Engineer
  timeperiod: Oct 2016 - Feb 2017
  tech_stack: Python, Druid, Pandas, MySQL, Flask, S3, Zookeeper, Vue.js, Kafka, Spark
  product_name: Predictive Maintenance Platform
  url: https://www.ascendo.ai
  description: 
    - d_item: Mapped data from various customer sources including CRM, service history, knowledge base to metadata model
    - d_item: Designed Druid based solution bringing down latency to under sub-second from usual timeouts in current system
    - d_item: Created data pipeline to ingest data to Druid using S3, Pandas
    - d_item: Designed and implemented restful APIs for consuming data from front-end using Flask
  
- company: Customer Centria
  place: Bangalore
  position: Software Engineer
  timeperiod: Jul 2015 - Aug 2016
  tech_stack: Backbone.js, Nvd3.js, Crossfilter.js, Java, Spring, MongoDB, Python, Mesos, Kafka, PostgreSQL
  product_name: CC Engage Platform
  url: https://www.customercentria.com
  description: 
    - d_item: Built dashboard for campaign analytics in Backbone.js Single Page App using Nvd3.js, Crossfilter.js
    - d_item: Developed APIs using Spring to integrate the product with Facebook Ads Network
    - d_item: Implemented module to pull tweets with interested keywords from twitter firehose and perform sentiment analysis




#     Created campaign analytics dashboard in Backbone.js Single Page 
#     Application, integrating d3.js and nvd3.js libraries into Omni-channel Campaign management SaaS product,
#      wrote REST API's for aggregating statistics from campaigns with Spring and MongoDB
    

#      Used Jenkins to create a CI / CD pipeline and automated reliable deployments

#  Proposed and managed a Mesos cluster for running applications and data workloads,
#      increasing developer productivity making deployments more resilient and manageable

#  Implemented a resilient pipeline to capture tweets based on keywords related 
#     to clients & perform sentiment analysis for a customer 360 data application with help from data scientists,
#      senior developers. Used Kafka, Python, MongoDB running on the Mesos Cluster


education:
- degree: M.Sc Physics, BITS Pilani University
  location: Goa
  timeperiod: 2009 - 2015

contact:
  email: rohith.reddi9@gmail.com
  phone: +91 888 654 0155
  github: rohithreddy
  website: rohithreddy.github.io
# en, de, fr, pt, ca, cn, it, es, th, pt-br, ru, sv, id, hu, pl, ja, ka, nl, he, zh-tw, lt, ko, el, nb-no
lang: en
`