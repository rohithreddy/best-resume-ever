/* #*/ export const PERSON = `
name:
  first: Rohith
  middle:
  last: Reddy
about: A Programmer with 4+ years of experience in building Data Intensive Applications that are simple and functional, tackling challenging architectural and scalability problems. In my free time I am either hacking Linux kernel or building embedded IoT devices.
# position: Software Programmer

computer_skills:
- type: Languages
  list: Python, Javascript, Java
- type: Frameworks
  list: Flask, Falcon, Pandas, Backbone.js, Airflow, Spring, Spark, Kafka, Chalice, Selenium, Dask
- type: Databases
  list: MySQL, PostgreSQL, MongoDB, Druid, DynamoDB, Redshift
- type: Dev tools
  list: Git, Nginx, Shell, Intellij, VS Code, Docker, AWS CDK
- type: Hosting
  list: AWS, GCP



experience:
- company: Sphota
  position: Member of Technical Staff
  timeperiod: Sep 2018 - Aug 2019

- company: Niyo
  position: Data Engineer
  timeperiod: Jun 2017 - Apr 2018

- company: RedBlackTree
  position: Serverside IOT Engineer
  timeperiod: Oct 2016 - Feb 2017
  
- company: Customer Centria
  position: Software Engineer
  timeperiod: Jul 2015 - Aug 2016


education:
- degree: M.Sc Physics, BITS Pilani University
  location: Goa
  timeperiod: 2009 - 2015

recentprojects:
- tech_stack: Falcon, PostgresQL, Python, PubSub, CloudFunctions, CloudScheduler, Vegeta
  year: 2019
  product_name: Paid Search Platform
  url: https://sphota.biz
  description: 
    - d_item: Developed high performance ad trackers for attribution modelling
    - d_item: Implemented a reporting system for marketeers to gain insights on Ad Spends
    - d_item: Made changes related to GDPR in internal data platform for a fortune 500 client
- tech_stack: Airflow, S3, Redshift, Metabase, Python, Pandas, Kafka, React.js, Spring, EC2
  year: 2018
  product_name: Niyo Fintech Products
  url: https://www.goniyo.com
  description: 
    - d_item: Created a centralized data warehouse on Redshift to handle txn data related to 0.5 million and growing user base
    - d_item: Developed BI system on Metabase, created investor dashboards that helped raise a funding of $14 million
    - d_item: Trained business & tech users in using the BI system, curated access, helping our organisation be data-driven
    - d_item: Implemented data quality checks, which found massive bugs in partner's APIs that we causing erroneous transactions 
    - d_item: Automated various reports for invoicing & sharing data with partners using Airflow
- tech_stack: Python, Druid, Pandas, Flask, S3, Zookeeper, Vue.js
  year: 2017
  product_name: Predictive Maintenance Platform
  url: https://www.ascendo.ai
  description: 
    - d_item: Mapped data from various customer sources including CRM, service history, knowledge base etc to a metadata model
    - d_item: Researched & proposed we use Druid as datastore instead of PostgreSQL, this brought down latency to sub-second from usual timeouts caused by filtering on huge number of dimensions
    - d_item: Developed services to ingest data to Druid using S3, Pandas
    - d_item: Designed and implemented APIs for consuming the data from front-end & ML services


contact:
  email: rohith.reddi9@gmail.com
  phone: +91 888 654 0155
  github: rohithreddy
  website: rohithreddy.github.io
# en, de, fr, pt, ca, cn, it, es, th, pt-br, ru, sv, id, hu, pl, ja, ka, nl, he, zh-tw, lt, ko, el, nb-no
lang: en
`